{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "96816ed7-b08a-4ca3-abb9-f99880c3535d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n",
    "\n",
    "This notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6482be4c-f067-47c9-b0ac-35c938b94601",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import findspark\n",
    "import random\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn import datasets\n",
    "import statistics as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "33fda74f-9885-47f0-812f-0b113c9966e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#read csv function, gets the location of the csv\n",
    "def read_csv(file_location):\n",
    "  #reading the csv\n",
    "  df = spark.read.csv(file_location, inferSchema = True, header = True)\n",
    "  #creating rdd\n",
    "  ds = df.rdd.collect()\n",
    "  size = len(df.columns) \n",
    "  lst = ['f' + str(i) for i in range(1, size)] # creating columns' names \n",
    "  #creating the list 'points' of the Points from the dataset \n",
    "  points = []\n",
    "  #creating labels list for the ARI evaluating\n",
    "  labels_true = []\n",
    "  for row in ds:\n",
    "    vec = []\n",
    "    #saving the labels\n",
    "    labels_true.append(row[\"class\"])\n",
    "    for col in lst:\n",
    "      vec.append(row[col])\n",
    "    points.append(vec)\n",
    "  # normalize the points\n",
    "  scaler = MinMaxScaler()\n",
    "  scaler.fit(points)\n",
    "  scaler.data_max_\n",
    "  norm_pts = scaler.transform(points)\n",
    "  points = norm_pts.tolist()\n",
    "  # convert the points list to rdd object\n",
    "  Pointsrdd = spark.sparkContext.parallelize(points)\n",
    "  return (points,Pointsrdd,labels_true)\n",
    "\n",
    "def kRandom(K, points):\n",
    "  #select random points from the dataset to be the initial centroids \n",
    "  centroids_index = random.sample(range(len(points)), K)\n",
    "  centroids = [points[i] for i in centroids_index]\n",
    "  return centroids\n",
    "\n",
    "def euclidean_distance(p, c):\n",
    "  #they have the same size\n",
    "  size = len(c)\n",
    "  dist = 0\n",
    "  # calculating the euclidean distance \n",
    "  for i in range(size):\n",
    "    dist += (p[i]-c[i])**2\n",
    "  return dist\n",
    "\n",
    "def centroidForPoint(p, C):\n",
    "  dist = []\n",
    "  for cent in C:\n",
    "    dist.append(oklidi(p, cent))\n",
    "  # each point's centroid is the closest one from all of the centroids  \n",
    "  ind = np.argmin(np.array(dist))\n",
    "  return ind\n",
    "\n",
    "def addPoints(x1, x2):\n",
    "  res_list = [x1[i] + x2[i] for i in range(len(x1))] # add between two points\n",
    "  return res_list\n",
    "\n",
    "def dividePoints(x1, num):\n",
    "  res_list = [x1[i] / num for i in range(len(x1))] # divide between two points\n",
    "  return res_list  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "540703ed-f9fd-420e-ba4a-443bdabe0c36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# K-means function\n",
    "def kMeans(dataset, K, CT = 0.0001, I = 30, Exp = 10):\n",
    "  Points = read_csv(dataset)\n",
    "  # true labels for the evaluation calculate\n",
    "  labels_true = Points[2] \n",
    "  #lists for the evaluation results\n",
    "  CH = []\n",
    "  ARI = []\n",
    "  #repeating the experiment \n",
    "  for i in range(Exp):\n",
    "    KCentroids = kRandom(K, Points[0])\n",
    "    iter = 0\n",
    "    dist = 1 # the convergence rate \n",
    "    while(iter < I and dist >= CT):\n",
    "      iter+=1\n",
    "      #mapping each point to it's centrid with \"centroidForPoint\"\n",
    "      mapper = Points[1].map(lambda p: (centroidForPoint(p, KCentroids), (p,1)))\n",
    "      #counting for each centroid the amount of points belong to it, adding between all of the points and numbering the centroids\n",
    "      #using reduceByKey\n",
    "      reducer = mapper.reduceByKey(lambda p1_c1, p2_c2: (addPoints(p1_c1[0],p2_c2[0]), p1_c1[1] + p2_c2[1]))\n",
    "      #calculate the new centroid, by the average for each cluster of points\n",
    "      newCents = reducer.map(lambda st: (st[0], dividePoints(st[1][0], st[1][1])))\n",
    "      #calculating the convergence rate by summerise the distances between the old centroids to the new ones\n",
    "      dist = np.sum(np.array([oklidi(newCents.collect()[i][1], KCentroids[i]) for i in range(newCents.count())]))\n",
    "      #saving the new centroids\n",
    "      KCentroids = [newCents.collect()[i][1] for i in range(newCents.count())]\n",
    "    # mapping according to the last iteration \n",
    "    mapper = Points[1].map(lambda p: (centroidForPoint(p, KCentroids), (p,1)))\n",
    "    #saving the points\n",
    "    X = np.array([np.array(mapper.collect()[i][1][0]) for i in range(mapper.count())])\n",
    "    #saving the pedictions\n",
    "    pred_labels = np.array([mapper.collect()[i][0] for i in range(mapper.count())])\n",
    "    #calculating CH\n",
    "    CH.append(metrics.calinski_harabasz_score(X, pred_labels))\n",
    "    #calculating ARI\n",
    "    ARI.append(metrics.adjusted_rand_score(labels_true, pred_labels))\n",
    "  mean_CH = st.mean(CH)\n",
    "  std_CH = st.stdev(CH)\n",
    "  mean_ARI = st.mean(ARI)\n",
    "  std_ARI = st.stdev(ARI)\n",
    "  return (mean_CH, std_CH, mean_ARI, std_ARI)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "94adffd8-5ed6-4c6b-9df5-b47a89524a74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Dataset: Iris\n",
       "K: 2\n",
       "CH results: (353.3674032325119, 0.0)\n",
       "ARI results: (0.5681159420289855, 0.0)\n",
       "----------------\n",
       "K: 3\n",
       "CH results: (325.636851378806, 64.52879625202748)\n",
       "ARI results: (0.6589834944504577, 0.1240147693366587)\n",
       "----------------\n",
       "K: 4\n",
       "CH results: (309.0472088242508, 11.82451518622369)\n",
       "ARI results: (0.6169774237144467, 0.021378460916023356)\n",
       "----------------\n",
       "K: 5\n",
       "CH results: (258.0474626382376, 23.792511121862415)\n",
       "ARI results: (0.5842797143221644, 0.06983342226190475)\n",
       "----------------\n",
       "K: 6\n",
       "CH results: (239.34047706394114, 18.374992126036208)\n",
       "ARI results: (0.5439978508841661, 0.08428515015455108)\n",
       "----------------\n",
       "Dataset: Glass\n",
       "K: 2\n",
       "CH results: (144.26860415096553, 0.0178630694293363)\n",
       "ARI results: (0.20448778249990288, 0.00642102440329792)\n",
       "----------------\n",
       "K: 3\n",
       "CH results: (100.50915534301221, 6.795016035515552)\n",
       "ARI results: (0.17935532089101838, 0.050740297897921095)\n",
       "----------------\n",
       "K: 4\n",
       "CH results: (86.4144912535335, 9.069569800175927)\n",
       "ARI results: (0.16382037290486087, 0.046333325815838745)\n",
       "----------------\n",
       "K: 5\n",
       "CH results: (76.67031801547593, 10.502749014756628)\n",
       "ARI results: (0.1544762075410894, 0.015598925150191784)\n",
       "----------------\n",
       "K: 6\n",
       "CH results: (70.9502273799478, 8.791857282905635)\n",
       "ARI results: (0.15068386429054126, 0.028304391007347423)\n",
       "----------------\n",
       "Dataset: Parkinson\n",
       "K: 2\n",
       "CH results: (84.21390242705209, 0.0025821392574052176)\n",
       "ARI results: (0.048027319991609634, 0.00338044099909771)\n",
       "----------------\n",
       "K: 3\n",
       "CH results: (76.93017559130062, 1.432387334127433)\n",
       "ARI results: (0.08600968285227245, 0.021006976152651735)\n",
       "----------------\n",
       "K: 4\n",
       "CH results: (71.18775860867049, 4.816677398383646)\n",
       "ARI results: (0.09057389554344954, 0.05039695140273273)\n",
       "----------------\n",
       "K: 5\n",
       "CH results: (62.34314545801948, 5.036539422785395)\n",
       "ARI results: (0.08230347106737526, 0.049746851543334164)\n",
       "----------------\n",
       "K: 6\n",
       "CH results: (58.57623359004984, 2.457781358105346)\n",
       "ARI results: (0.08215921403574059, 0.03811777751520097)\n",
       "----------------\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Dataset: Iris\nK: 2\nCH results: (353.3674032325119, 0.0)\nARI results: (0.5681159420289855, 0.0)\n----------------\nK: 3\nCH results: (325.636851378806, 64.52879625202748)\nARI results: (0.6589834944504577, 0.1240147693366587)\n----------------\nK: 4\nCH results: (309.0472088242508, 11.82451518622369)\nARI results: (0.6169774237144467, 0.021378460916023356)\n----------------\nK: 5\nCH results: (258.0474626382376, 23.792511121862415)\nARI results: (0.5842797143221644, 0.06983342226190475)\n----------------\nK: 6\nCH results: (239.34047706394114, 18.374992126036208)\nARI results: (0.5439978508841661, 0.08428515015455108)\n----------------\nDataset: Glass\nK: 2\nCH results: (144.26860415096553, 0.0178630694293363)\nARI results: (0.20448778249990288, 0.00642102440329792)\n----------------\nK: 3\nCH results: (100.50915534301221, 6.795016035515552)\nARI results: (0.17935532089101838, 0.050740297897921095)\n----------------\nK: 4\nCH results: (86.4144912535335, 9.069569800175927)\nARI results: (0.16382037290486087, 0.046333325815838745)\n----------------\nK: 5\nCH results: (76.67031801547593, 10.502749014756628)\nARI results: (0.1544762075410894, 0.015598925150191784)\n----------------\nK: 6\nCH results: (70.9502273799478, 8.791857282905635)\nARI results: (0.15068386429054126, 0.028304391007347423)\n----------------\nDataset: Parkinson\nK: 2\nCH results: (84.21390242705209, 0.0025821392574052176)\nARI results: (0.048027319991609634, 0.00338044099909771)\n----------------\nK: 3\nCH results: (76.93017559130062, 1.432387334127433)\nARI results: (0.08600968285227245, 0.021006976152651735)\n----------------\nK: 4\nCH results: (71.18775860867049, 4.816677398383646)\nARI results: (0.09057389554344954, 0.05039695140273273)\n----------------\nK: 5\nCH results: (62.34314545801948, 5.036539422785395)\nARI results: (0.08230347106737526, 0.049746851543334164)\n----------------\nK: 6\nCH results: (58.57623359004984, 2.457781358105346)\nARI results: (0.08215921403574059, 0.03811777751520097)\n----------------\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run\n",
    "dataset1 = \"/FileStore/tables/iris-1.csv\"\n",
    "dataset2 = \"/FileStore/tables/glass-1.csv\"\n",
    "dataset3 = \"/FileStore/tables/parkinsons-3.csv\"\n",
    "datasets = [dataset1, dataset2, dataset3]\n",
    "\n",
    "for ds in range(len(datasets)):\n",
    "  if ds == 0:\n",
    "    name = \"Iris\"\n",
    "  elif ds == 1:\n",
    "    name = \"Glass\"\n",
    "  elif ds == 2:\n",
    "    name = \"Parkinson\"\n",
    "  print(\"Dataset: \" + name)\n",
    "  for K in range(2, 7):\n",
    "    print(\"K: \" + str(K))\n",
    "    result = kMeans(datasets[ds], K)\n",
    "    print(\"CH results: \" + str((result[0], result[1])))\n",
    "    print(\"ARI results: \" + str((result[2], result[3])))\n",
    "    print(\"----------------\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "2021-06-02 - DBFS Example",
   "notebookOrigID": 2031965495695753,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
